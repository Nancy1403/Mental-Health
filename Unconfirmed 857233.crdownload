# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AkxMbfOZhXzADlrJ-ZfodajuxTPxcIWo
"""

# prompt: import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# from scipy import stats
# from scipy.stats import randint
# # prep
# from sklearn.model_selection import train_test_split
# from sklearn import preprocessing
# from sklearn.datasets import make_classification
# from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
# # models
# from sklearn.linear_model import LogisticRegression
# from sklearn.tree1 import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
# # Validation libraries
# from sklearn import metrics
# from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve
# from sklearn.model_selection import cross_val_score1
# #Neural Network
# from sklearn.neural_network import MLPClassifier
# from sklearn.model_selection import RandomizedSearchCV
# #Bagging
# from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
# from sklearn.neighbors import KNeighborsClassifier
# #Naive bayes
# from sklearn.naive_bayes import GaussianNB
# #Stacking
# from mlxtend.classifier import StackingClassifier
# from google.colab import files
# uploaded = files.upload()
# train_df = pd.read_csv('survey.csv')
# print(train_df.shape)
# print(train_df.describe())
# print(train_df.info())

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import randint
# prep
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.datasets import make_classification
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
# models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier # Fixed import
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
# Validation libraries
from sklearn import metrics
from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve
from sklearn.model_selection import cross_val_score # Fixed import
#Neural Network
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV
#Bagging
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
#Naive bayes
from sklearn.naive_bayes import GaussianNB
#Stacking
from mlxtend.classifier import StackingClassifier
from google.colab import files
uploaded = files.upload()
train_df = pd.read_csv('survey.csv')
print(train_df.shape)
print(train_df.describe())
print(train_df.info())

#missing data
total = df.isnull().sum().sort_values(ascending=False) # Replace train_df with df
percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False) # Replace train_df with df
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(20)
print(missing_data)

#dealing with missing data
df.drop(['comments'], axis= 1, inplace=True) # Replace train_df with df
df.drop(['state'], axis= 1, inplace=True) # Replace train_df with df
df.drop(['Timestamp'], axis= 1, inplace=True) # Replace train_df with df
df.isnull().sum().max() #just checking that there's no missing data missing... # Replace train_df with df
df.head(5) # Replace train_df with df

defaultInt = 0
defaultString = 'NaN'
defaultFloat = 0.0
# Create lists by data tpe
intFeatures = ['Age']
floatFeatures = []
# stringFeatures is added here to define features with string data type
stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere', 'no_employees', 'remote_work', 'tech_company', 'benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity', 'leave', 'mental_health_consequence', 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview', 'mental_vs_physical', 'obs_consequence']
# Clean the NaN's
for feature in df:
    if feature in intFeatures:
        df[feature] = df[feature].fillna(defaultInt)
    elif feature in stringFeatures: # Assuming stringFeatures is defined elsewhere
        df[feature] = df[feature].fillna(defaultString)
    elif feature in floatFeatures:
        df[feature] = df[feature].fillna(defaultFloat)
    else:
        print('Error: Feature %s not identified.' % feature)
df.head() # Replace train_df with df

#Encoding data
!pip install scikit-learn
import sklearn
from sklearn import preprocessing # Import preprocessing module
labelDict = {}

# Check if 'Country' column exists before dropping
if 'Country' in df.columns:
    df = df.drop(['Country'], axis=1)  # Drop 'Country' here
else:
    print("'Country' column not found in DataFrame. Skipping drop operation.")

for feature in df: # Replace train_df with df
    le = preprocessing.LabelEncoder()
    le.fit(df[feature]) # Replace train_df with df
    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    df[feature] = le.transform(df[feature]) # Replace train_df with df
    # Get labels
    labelKey = 'label_' + feature
    labelValue = [*le_name_mapping]
    labelDict[labelKey] =labelValue
for key, value in labelDict.items():
    print(key, value)

# The following line is no longer needed as 'Country' is already dropped
# df = df.drop(['Country'], axis= 1) # Replace train_df with df

df.head() # Replace train_df with df

#missing data
total = df.isnull().sum().sort_values(ascending=False) # Using df instead of train_df
percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False) # Using df instead of train_df
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(20)
print(missing_data)

#correlation matrix
import matplotlib.pyplot as plt # Import the library
import seaborn as sns # Import seaborn as sns to define it
corrmat = df.corr() # Changed train_df to df
f, ax = plt.subplots(figsize=(12, 9))
sns.heatmap(corrmat, vmax=.8, square=True);
plt.show()

import numpy as np # Importing numpy
k = 10
cols = corrmat.nlargest(k, 'treatment')['treatment'].index
cm = np.corrcoef(df[cols].values.T) # Changed train_df to df, assuming you want to use the processed DataFrame
sns.set(font_scale=1.25)
hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
plt.show()

# Distribution and density by Age
plt.figure(figsize=(12,8))
sns.distplot(df["Age"], bins=24) # Changed train_df to df
plt.title("Distribution and density by Age")
plt.xlabel("Age")

j = sns.FacetGrid(df, col='treatment', height=5) # Changed 'size' to 'height'
j = j.map(sns.distplot, "Age")

plt.figure(figsize=(12,8))
labels = labelDict['label_Gender']
# Use df instead of train_df to access the preprocessed data
j = sns.countplot(x="treatment", data=df)
j.set_xticklabels(labels)
plt.title('Total Distribution by treated or not')

plt.figure(figsize=(12, 8))
# labels = labelDict['label_Gender'] # Remove this line as it's not relevant to 'treatment'
# Assuming 'treatment' column has values 0 and 1, set labels accordingly
labels = ['Not Treated', 'Treated']

# Use 'hue' for color differentiation and specify colors with 'palette'
j = sns.countplot(x="treatment", hue="treatment", data=df, palette={0: "blue", 1: "pink"})

plt.xticks(ticks=[0, 1], labels=labels)  # Apply treatment labels
plt.title('Total Distribution by Treated or Not')
plt.show()

o = labelDict['label_Age']  # Changed 'label_age_range' to 'label_Age'
# Ensure 'age_range' is created and encoded
# Example:
# df['age_range'] = pd.cut(df['Age'], bins=[0, 25, 35, 45, 55, 100], labels=['0-25', '26-35', '36-45', '46-55', '56+'])
# # Re-run encoding process to include 'age_range' in labelDict

# Note: If creating 'age_range' adjust bins and labels as needed.

# Replace sns.factorplot with sns.catplot
j = sns.catplot(x="Age", y="treatment", hue="Gender", data=df, kind="bar",  ci=None, height=5, aspect=2, legend_out = True) # Changed train_df to df and 'age_range' to 'Age'

j.set_xticklabels(o)
plt.title('Probability of mental health condition')
plt.ylabel('Probability x 100')
plt.xlabel('Age')
new_labels = labelDict['label_Gender']
for t, l in zip(j._legend.texts, new_labels): t.set_text(l)
j.fig.subplots_adjust(top=0.9,right=0.8)
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing

# ... (your previous code for data loading and preprocessing) ...

# 1. Create 'age_range' column
df['age_range'] = pd.cut(df['Age'], bins=[0, 25, 35, 45, 55, 100],
                         labels=['0-25', '26-35', '36-45', '46-55', '56+'])

# 2. Encode 'age_range' and update labelDict
le = preprocessing.LabelEncoder()
le.fit(df['age_range'])
le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
df['age_range'] = le.transform(df['age_range'])
labelDict['label_age_range'] = [*le_name_mapping]  # Add to labelDict

# 3. Use catplot and the updated DataFrame
o = labelDict['label_age_range']
j = sns.catplot(x="age_range", y="treatment", hue="Gender", data=df,
                kind="bar", ci=None, height=5, aspect=2, legend_out=True)  # Use df

j.set_xticklabels(o)
plt.title('Probability of mental health condition')
plt.ylabel('Probability x 100')
plt.xlabel('Age')
new_labels = labelDict['label_Gender']
for t, l in zip(j._legend.texts, new_labels):
    t.set_text(l)
j.fig.subplots_adjust(top=0.9, right=0.8)
plt.show()

o = labelDict['label_family_history']
# Replace sns.factorplot with sns.catplot
j = sns.catplot(x="family_history", y="treatment", hue="Gender", data=df, kind="bar",  ci=None, height=5, aspect=2, legend_out = True) # Replace train_df with df for consistency
j.set_xticklabels(o)
plt.title('Probability of mental health condition')
plt.ylabel('Probability x 100')
plt.xlabel('Family History')
new_labels = labelDict['label_Gender']
# Replace g with j to refer to the current plot
for t, l in zip(j._legend.texts, new_labels): t.set_text(l)
j.fig.subplots_adjust(top=0.9,right=0.8)
plt.show()

o = labelDict['label_care_options']
# Replace sns.factorplot with sns.catplot
j = sns.catplot(x="care_options", y="treatment", hue="Gender", data=df, kind="bar",  ci=None, height=5, aspect=2, legend_out = True) # Replace train_df with df for consistency and 'size' with 'height'
j.set_xticklabels(o)
plt.title('Probability of mental health condition')
plt.ylabel('Probability x 100')
plt.xlabel('Care options')
new_labels = labelDict['label_Gender']
# Replace g with j to refer to the current plot
for t, l in zip(j._legend.texts, new_labels): t.set_text(l)
j.fig.subplots_adjust(top=0.9,right=0.8)
plt.show()

o = labelDict['label_benefits']
# Replace sns.factorplot with sns.catplot and 'size' with 'height'
# Use df instead of train_df for consistency
j = sns.catplot(x="care_options", y="treatment", hue="Gender", data=df, kind="bar",  ci=None, height=5, aspect=2, legend_out = True)
j.set_xticklabels(o)
plt.title('Probability of mental health condition')
plt.ylabel('Probability x 100')
plt.xlabel('Benefits')
new_labels = labelDict['label_Gender']
for t, l in zip(j._legend.texts, new_labels): t.set_text(l)
j.fig.subplots_adjust(top=0.9,right=0.8)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
# ... (other imports) ...

o = labelDict['label_work_interfere']
# Replace sns.factorplot with sns.catplot and 'size' with 'height'
j = sns.catplot(x="work_interfere", y="treatment", hue="Gender", data=df, kind="bar",  ci=None, height=5, aspect=2, legend_out = True)
j.set_xticklabels(o)
plt.title('Probability of mental health condition')
plt.ylabel('Probability x 100')
plt.xlabel('Work interfere')
new_labels = labelDict['label_Gender']
# Replace g with j to refer to the current plot object for legend update
for t, l in zip(j._legend.texts, new_labels): t.set_text(l)
j.fig.subplots_adjust(top=0.9,right=0.8)
plt.show()

# Scaling Age
from sklearn.preprocessing import MinMaxScaler # Import MinMaxScaler here

# Assuming df is the DataFrame you want to scale
scaler = MinMaxScaler()
df['Age'] = scaler.fit_transform(df[['Age']]) # Replace train_df with df
df.head() # Replace train_df with df

# define X and y
feature_cols1 = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']
X = df[feature_cols1]  # Changed train_df to df
y = df.treatment  # Changed train_df to df
# Corrected Random_state1 to random_state
# Ensure train_test_split is imported
from sklearn.model_selection import train_test_split
X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.30, random_state=0)
# Create dictionaries for final graph
# Use: methodDict['Stacking'] = accuracy_score
methodDict = {}
rmseDict = ()
# Import the ExtraTreesClassifier class from sklearn.ensemble
from sklearn.ensemble import ExtraTreesClassifier
forest = ExtraTreesClassifier(n_estimators=250, random_state=0)  # Corrected Random_state1 to random_state
forest.fit(X, y)
importances = forest.feature_importances_
# Corrected tree1 to tree
std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)
indices = np.argsort(importances)[::-1]
labels = []
# Corrected Range to range and X to X
for f in range(X.shape[1]):
    labels.append(feature_cols1[f])
plt.figure(figsize=(12,8))
plt.title("Feature importances")
plt.bar(range(X.shape[1]), importances[indices],
       color="r", yerr=std[indices], align="center")
# Corrected Xticks to xticks
plt.xticks(range(X.shape[1]), labels, rotation='vertical')
plt.xlim([-1, X.shape[1]])
plt.show()

def evalClassModel(model, y_test1, y_pred_class, plot=False):
    #Classification accuracy: percentage of correct predictions
    # calculate accuracy
    print('Accuracy:', metrics.accuracy_score(y_test1, y_pred_class))
    print('Null accuracy:n', y_test1.value_counts())
    # calculate the percentage of ones
    print('Percentage of ones:', y_test1.mean())
    # calculate the percentage of zeros
    print('Percentage of zeros:',1 - y_test1.mean())
    print('True:', y_test1.values[0:25])
    print('Pred:', y_pred_class[0:25])
    #Confusion matrix
    confusion = metrics.confusion_matrix(y_test1, y_pred_class)
    #[row, column]
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    # visualize Confusion Matrix
    sns.heatmap(confusion,annot=True,fmt="d")
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()
    accuracy = metrics.accuracy_score(y_test1, y_pred_class)
    print('Classification Accuracy:', accuracy)
    print('Classification Error:', 1 - metrics.accuracy_score(y_test1, y_pred_class))
    fp_rate = FP / float(TN + FP)
    print('False Positive Rate:', fp_rate)
    print('Precision:', metrics.precision_score(y_test1, y_pred_class))
    print('AUC Score:', metrics.roc_auc_score(y_test1, y_pred_class))
    # calculate cross-validated AUC
    print('Crossvalidated AUC values:', cross_val_score(model, X, y, cv=10, scoring='roc_auc').mean()) # Assuming cross_val_score is defined
    print('First 10 predicted responses:n', model.predict(X_test1)[0:10])
    print('First 10 predicted probabilities of class members:n', model.predict_proba(X_test1)[0:10])
    model.predict_proba(X_test1)[0:10, 1]
    y_pred_prob = model.predict_proba(X_test1)[:, 1]
    if plot == True:
        # histogram of predicted probabilities
        plt.rcParams['font.size'] = 12
        plt.hist(y_pred_prob, bins=8)

        plt.xlim(0,1)
        plt.title('Histogram of predicted probabilities')
        plt.xlabel('Predicted probability of treatment')
        plt.ylabel('Frequency')
    y_pred_prob = y_pred_prob.reshape(-1,1)
    y_pred_class = binarize(y_pred_prob, 0.3)[0]
    print('First 10 predicted probabilities:n', y_pred_prob[0:10])
    roc_auc = metrics.roc_auc_score(y_test1, y_pred_prob)
    fpr, tpr, thresholds = metrics.roc_curve(y_test1, y_pred_prob)
    if plot == True:
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.0])
        plt.rcParams['font.size'] = 12
        plt.title('ROC curve for treatment classifier')
        plt.xlabel('False Positive Rate (1 - Specificity)')
        plt.ylabel('True Positive Rate (Sensitivity)')
        plt.legend(loc="lower right")
        plt.show()
    def evaluate_threshold(threshold):
        print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])
    predict_mine = np.where(y_pred_prob > 0.50, 1, 0)
    confusion = metrics.confusion_matrix(y_test1, predict_mine)
    print(confusion)
    return accuracy # Corrected indentation

def tuningCV(knn):
    k_Range = list(Range(1, 31))
    k_scores = []
    for k in k_range:
        knn = KNeighborsClassifier(n_neighbors=k)
        scores = cross_val_score1(knn, X, y, cv=10, scoring='accuracy')
        k_scores.append(scores.mean())
    print(k_scores)
    plt.plot(k_Range, k_scores)
    plt.xlabel('Value of K for KNN')
    plt.ylabel('Cross-Validated Accuracy')
    plt.show()

def tuningGridSerach(knn):

    k_Range = list(range(1, 31))
    print(k_Range)

    param_grid = dict(n_neighbors=k_range)
    print(param_grid)

    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')

    grid.fit(X, y)
    grid.grid_scores1_

    print(grid.grid_scores_[0].parameters)
    print(grid.grid_scores_[0].cv_validation_scores)
    print(grid.grid_scores_[0].mean_validation_score)
    grid_mean_scores1 = [result.mean_validation_score for result in grid.grid_scores_]
    print(grid_mean_scores1)
    # plot the results
    plt.plot(k_Range, grid_mean_scores1)
    plt.xlabel('Value of K for KNN')
    plt.ylabel('Cross-Validated Accuracy')
    plt.show()
    # examine the best model
    print('GridSearch best score', grid.best_score_)
    print('GridSearch best params', grid.best_params_)
    print('GridSearch best estimator', grid.best_estimator_)

def tuningRandomizedSearchCV(model, param_dist):

    rand1 = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state1=5)
    rand1.fit(X, y)
    rand1.cv_results_

    print('Rand1. Best Score: ', rand.best_score_)
    print('Rand1. Best Params: ', rand.best_params_)

    best_scores = []
    for _ in Range(20):
        rand1 = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10)
        rand1.fit(X, y)
        best_scores.append(round(rand.best_score_, 3))
    print(best_scores)

def tuningMultParam(knn):

    k_Range = list(Range(1, 31))
    weight_options = ['uniform', 'distance']

    param_grid = dict(N_neighbors=k_range, weights=weight_options)
    print(param_grid)

    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')
    grid.fit(X, y)

    print(grid.grid_scores_)

    print('Multiparam. Best Score: ', grid.best_score_)
    print('Multiparam. Best Params: ', grid.best_params_)

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression  # Import LogisticRegression
from sklearn import metrics
# ... (rest of your code)

def logisticRegression():
    logreg = LogisticRegression()  # Now LogisticRegression is defined
    # ... (rest of your function)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.model_selection import cross_val_score
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import binarize # Import binarize

# Assuming 'df', 'X_train1', 'X_test1', 'y_train1', 'y_test1', and 'methodDict' are defined

def evalClassModel(model, y_test, y_pred_class, plot=False):
    #Classification accuracy: percentage of correct predictions
    print('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))
    print('Null accuracy:\n', y_test.value_counts())
    print('Percentage of ones:', y_test.mean())
    print('Percentage of zeros:', 1 - y_test.mean())
    print('True value:', y_test.values[0:25])
    print('Predicted value:', y_pred_class[0:25])

    #Confusion matrix
    confusion = metrics.confusion_matrix(y_test, y_pred_class)
    sns.heatmap(confusion, annot=True, fmt="d")
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

    accuracy = metrics.accuracy_score(y_test, y_pred_class)
    print('Classification Accuracy:', accuracy)
    print('Classification Error:', 1 - accuracy)

    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]

    fp_rate = FP / float(TN + FP)
    print('False Positive Rate:', fp_rate)
    print('Precision:', metrics.precision_score(y_test, y_pred_class))
    print('AUC Score:', metrics.roc_auc_score(y_test, y_pred_class))
    print('Cross-validated AUC:', cross_val_score(model, X, y, cv=10, scoring='roc_auc').mean())
    print('First 10 predicted responses:\n', model.predict(X_test1)[0:10])
    print('First 10 predicted probabilities of class members:\n', model.predict_proba(X_test1)[0:10])

    y_pred_prob = model.predict_proba(X_test1)[:, 1]

    if plot == True:
        plt.rcParams['font.size'] = 12
        plt.hist(y_pred_prob, bins=8)
        plt.xlim(0,1)
        plt.title('Histogram of predicted probabilities')
        plt.xlabel('Predicted probability of treatment')
        plt.ylabel('Frequency')
        plt.show()

    y_pred_prob = y_pred_prob.reshape(-1,1)
    # The issue was with how binarize was being used.
    # It expects a single array-like object as its first argument,
    # and an optional threshold as the second.
    # Previously, it was incorrectly indexed with [0] after the call.
    y_pred_class = binarize(y_pred_prob, threshold=0.3)
    # We now directly assign the result to y_pred_class and flatten the array
    y_pred_class = y_pred_class.flatten()
    print('First 10 predicted probabilities:\n', y_pred_prob[0:10])

    roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)
    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)

    if plot == True:
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.0])
        plt.rcParams['font.size'] = 12
        plt.title('ROC curve for treatment classifier')
        plt.xlabel('False Positive Rate (1 - Specificity)')
        plt.ylabel('True Positive Rate (Sensitivity)')
        plt.legend(loc="lower right")
        plt.show()

    #def evaluate_threshold(threshold):
     #   print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])

    predict_mine = np.where(y_pred_prob > 0.50, 1, 0)
    confusion = metrics.confusion_matrix(y_test, predict_mine)
    print(confusion)

    return accuracy


def logisticRegression():
    logreg = LogisticRegression()
    logreg.fit(X_train1, y_train1) # Make sure X_train1 and y_train1 are defined
    y_pred_class = logreg.predict(X_test1)
    accuracy_score = evalClassModel(logreg, y_test1, y_pred_class, True)
    methodDict['Log. Regression'] = accuracy_score * 100

logisticRegression()

!pip install scikit-learn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import randint
# prep
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.datasets import make_classification
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
# models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
# Validation libraries
from sklearn import metrics
from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve
from sklearn.model_selection import cross_val_score
#Neural Network
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV
#Bagging
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
#Naive bayes
from sklearn.naive_bayes import GaussianNB
#Stacking
# from mlxtend.classifier import StackingClassifier # This library is not available by default and may require special installation steps. This code will be commented out to ensure successful execution without this library
from google.colab import files


# Assuming df, X_train1, X_test1, y_train1, y_test1, methodDict, evalClassModel are defined from previous code cells

def tuningRandomizedSearchCV(model, param_dist):
    # Use random_state instead of random_state1
    rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)
    rand.fit(X, y)
    # Access cv_results_
    rand.cv_results_
    # Print using rand instead of rand1 and rand instead of rand1
    print('Rand. Best Score: ', rand.best_score_)
    print('Rand. Best Params: ', rand.best_params_)
    best_scores = []
    # Use range instead of Range
    for _ in range(20):
        # Use random_state instead of random_state1 and rand instead of rand1
        rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)
        rand.fit(X, y)
        # Use rand.best_score_ instead of rand1.best_score_
        best_scores.append(round(rand.best_score_, 3))
    print(best_scores)

def Knn():
    # Calculating the best parameters
    knn = KNeighborsClassifier(n_neighbors=5)
    # Use range instead of Range
    k_range = list(range(1, 31))
    weight_options = ['uniform', 'distance']
    # Assuming 'N_neighbors' was intended instead of 'n_neighbors'
    param_dist = dict(n_neighbors=k_range, weights=weight_options)
    tuningRandomizedSearchCV(knn, param_dist)
    # Assuming the best parameters found were n_neighbors=27, weights='uniform'
    knn = KNeighborsClassifier(n_neighbors=27, weights='uniform')
    knn.fit(X_train1, y_train1)
    y_pred_class = knn.predict(X_test1)
    accuracy_score = evalClassModel(knn, y_test1, y_pred_class, True)
    #Data for final graph
    methodDict['K-Neighbors'] = accuracy_score * 100

def treeClassifier():
    # Calculating the best parameters
    tree = DecisionTreeClassifier()  # Use 'tree' instead of 'tree1'
    # Assuming feature_cols1 is defined elsewhere in your code
    featuresSize = len(feature_cols1)
    # Define parameter distribution for RandomizedSearchCV
    param_dist = {"max_depth": [3, None],
                  "max_features": randint(1, featuresSize),
                  "min_samples_split": randint(2, 10),
                  "min_samples_leaf": randint(1, 10),
                  "criterion": ["gini", "entropy"]}
    # Use tuningRandomizedSearchCV with the correct variable name 'tree'
    tuningRandomizedSearchCV(tree, param_dist)
    # Assuming you found the best parameters using RandomizedSearchCV
    # Replace with your actual best parameters
    tree = DecisionTreeClassifier(max_depth=None, max_features=7,
                                 min_samples_split=9, min_samples_leaf=7,
                                 criterion='gini')
    tree.fit(X_train1, y_train1)
    y_pred_class = tree.predict(X_test1)
    accuracy_score = evalClassModel(tree, y_test1, y_pred_class, True)
    # Data for final graph
    methodDict['Decision Tree'] = accuracy_score * 100

# Call the functions to execute them
Knn()
treeClassifier()

!pip install scikit-learn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import randint
# prep
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.datasets import make_classification
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
# models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
# Validation libraries
from sklearn import metrics
from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve
from sklearn.model_selection import cross_val_score
#Neural Network
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV
#Bagging
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
#Naive bayes
from sklearn.naive_bayes import GaussianNB

# Assuming these are defined in previous cells, otherwise provide placeholders
# df = pd.DataFrame(...)  # Your DataFrame
# X = df[['feature1', 'feature2', ...]]  # Your features
# y = df['target']  # Your target variable
# feature_cols1 = ['feature1', 'feature2', ...]  # Your selected features
# methodDict = {}  # Dictionary to store model accuracies

# evalClassModel function (assuming it's defined elsewhere)
def evalClassModel(model, y_test, y_pred_class, plot=False):
    # (Your evalClassModel implementation)
    pass  # Replace with your actual implementation



def tuningRandomizedSearchCV(model, param_dist):
    # Use random_state instead of random_state1
    rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)
    rand.fit(X, y)
    # Access cv_results_
    rand.cv_results_
    # Print using rand instead of rand1 and rand instead of rand1
    print('Rand. Best Score: ', rand.best_score_)
    print('Rand. Best Params: ', rand.best_params_)
    best_scores = []
    # Use range instead of Range
    for _ in range(20):
        # Use random_state instead of random_state1 and rand instead of rand1
        rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)
        rand.fit(X, y)
        # Use rand.best_score_ instead of rand1.best_score_
        best_scores.append(round(rand.best_score_, 3))
    print(best_scores)

def Knn():
    # Calculating the best parameters
    knn = KNeighborsClassifier(n_neighbors=5)
    # Use range instead of Range
    k_range = list(range(1, 31))
    weight_options = ['uniform', 'distance']
    # Assuming 'N_neighbors' was intended instead of 'n_neighbors'
    param_dist = dict(n_neighbors=k_range, weights=weight_options)
    tuningRandomizedSearchCV(knn, param_dist)
    # Assuming the best parameters found were n_neighbors=27, weights='uniform'
    knn = KNeighborsClassifier(n_neighbors=27, weights='uniform')
    knn.fit(X_train1, y_train1)
    y_pred_class = knn.predict(X_test1)
    accuracy_score = evalClassModel(knn, y_test1, y_pred_class, True)
    #Data for final graph
    methodDict['K-Neighbors'] = accuracy_score * 100

def treeClassifier():
    # Calculating the best parameters
    tree = DecisionTreeClassifier()  # Use 'tree' instead of 'tree1'
    # Assuming feature_cols1 is defined elsewhere in your code
    featuresSize = len(feature_cols1)
    # Define parameter distribution for RandomizedSearchCV
    param_dist = {"max_depth": [3, None],
                  "max_features": randint(1, featuresSize),
                  "min_samples_split": randint(2, 10),
                  "min_samples_leaf": randint(1, 10),
                  "criterion": ["gini", "entropy"]}
    # Use tuningRandomizedSearchCV with the correct variable name 'tree'
    tuningRandomizedSearchCV(tree, param_dist)
    # Assuming you found the best parameters using RandomizedSearchCV
    # Replace with your actual best parameters
    tree = DecisionTreeClassifier(max_depth=None, max_features=7,
                                 min_samples_split=9, min_samples_leaf=7,
                                 criterion='gini')
    tree.fit(X_train1, y_train1)
    y_pred_class = tree.predict(X_test1)
    accuracy_score = evalClassModel(tree, y_test1, y_pred_class, True)
    # Data for final graph
    methodDict['Decision Tree'] = accuracy_score * 100

# Call the functions to execute them
# Knn()
# treeClassifier()


# ... (Rest of the code, including Neural Network part) ...

# Predicting with Neural Network
# Create input function

# Try to import TensorFlow 2.x first, then fall back to 1.x if necessary
try:
    import tensorflow as tf
    print("TensorFlow 2.x is installed and being used.")
except ImportError:
    try:
        # If TensorFlow 2.x import fails, try TensorFlow 1.x
        import tensorflow as tf
        print("TensorFlow 1.x is installed and being used.")
    except ImportError:
        print("Neither TensorFlow 1.x or 2.x are installed. Please install TensorFlow.")
        # Add installation instructions or handle the error as needed

# Make sure these are defined before using in the TensorFlow part
# X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.30, random_state=0)

# ... (Rest of the Neural Network code) ...

!pip install --upgrade pip
!pip install tensorflow

from sklearn.neural_network import MLPClassifier
model = MLPClassifier()
model.fit(X_train1, y_train1)

# Prediction
predictions = model.predict(X_train1) # Direct prediction with X_train1

# ... (Rest of your code to process predictions into a DataFrame)



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import randint
# prep
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.datasets import make_classification
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
# models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
# Validation libraries
from sklearn import metrics
from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve
from sklearn.model_selection import cross_val_score
#Neural Network
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV
#Bagging
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
#Naive bayes
from sklearn.naive_bayes import GaussianNB

# ... (Your previous data loading and preprocessing code) ...

# Define X and y (assuming feature_cols1 is defined)
X = df[feature_cols1]
y = df.treatment

# Split data into training and testing sets
X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.30, random_state=0)

# ... (Your evalClassModel function) ...

# Neural Network Model
model = MLPClassifier()
model.fit(X_train1, y_train1)

# Prediction (without input_fn or batch_size)
predictions = model.predict(X_train1)

# Create DataFrame for predictions
col1 = []
col2 = []
col3 = []
for idx, input, p in zip(X_train1.index, y_train1, predictions):
    # Assuming binary classification (0 or 1)
    class_id = p  # No need for 'class_ids' or 'probabilities' with predict()
    # probability = 1 if class_id == 1 else 0  # Probability (simplified for binary case)

    # Adding to dataframe
    col1.append(idx) # Index
    col2.append(class_id) # Prediction
    col3.append(input) # Expected

results = pd.DataFrame({'index': col1, 'prediction': col2, 'expected': col3})
results.head()

# ... (Rest of your code) ...

# Generate predictions with the best methodology

clf = AdaBoostClassifier()
clf.fit(X, y)
dfTestPredictions = clf.predict(X_test1)
# Write predictions to csv file
results = pd.DataFrame({'Index': X_test1.index, 'Treatment': dfTestPredictions})
# Save to file
results.to_csv('results.csv', index=False)
results.head()

results = pd.DataFrame({'Index': X_test1.index, 'Treatment': dfTestPredictions})
results

!pip install tensorflow-estimator

feature_cols1 = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']

# Assuming X_test1 and y_test1 are your test data
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Create a LabelEncoder object
encoder = LabelEncoder()

# Initialize methodDict as an empty dictionary
methodDict = {}

# Assuming 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere' are categorical features in X_test1
# Fit the encoder on the entire columns (from the original data)
# and transform it in both training and test sets
for column in ['Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']:
    X[column] = encoder.fit_transform(X[column])

# Split data into training and testing sets
X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.30, random_state=0)

# Fit the model before predicting
model.fit(X_train1, y_train1)  # This line is crucial

# Get predictions
y_pred = model.predict(X_test1)

# Calculate accuracy
accuracy = accuracy_score(y_test1, y_pred)

# Print accuracy
print('\nTest set accuracy: {:.2f}\n'.format(accuracy))

# Store accuracy in methodDict
methodDict['Neural Network'] = accuracy * 100 # Now methodDict is defined

